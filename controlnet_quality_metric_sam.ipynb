{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31892e49",
   "metadata": {},
   "source": [
    "# ControlNet Quality Metric using SAM Segmentation & Hungarian Matching\n",
    "\n",
    "This notebook evaluates the quality of ControlNet image generation by:\n",
    "1. **Extracting segments** from the original COCO segmentation map (colored regions)\n",
    "2. **Segmenting** the two generated images using SAM (Segment Anything Model):\n",
    "   - ControlNet + Spatial Conditioning (conditioned on segmentation maps)\n",
    "   - ControlNet without Spatial Conditioning\n",
    "3. **Treating all segments as class-agnostic** (same class)\n",
    "4. **Using Hungarian algorithm** to find optimal segment matching\n",
    "5. **Computing maximum IoU** between matched segments\n",
    "\n",
    "**Key Insight**: The original image is a segmentation map from COCO dataset with colored regions. We extract masks from these colored regions and match them against SAM-generated masks from the two generated images using Hungarian matching to maximize IoU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9bb135",
   "metadata": {},
   "source": [
    "## 1. Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad75c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision\n",
    "!pip install -q opencv-python matplotlib numpy scipy\n",
    "!pip install -q git+https://github.com/facebookresearch/segment-anything.git\n",
    "!pip install -q pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c2e66",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defdfe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SAM imports\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb17c5cd",
   "metadata": {},
   "source": [
    "## 3. Download and Load SAM Model\n",
    "\n",
    "SAM comes in 3 sizes:\n",
    "- **vit_h (huge)**: Best quality, slower\n",
    "- **vit_l (large)**: Good balance\n",
    "- **vit_b (base)**: Faster, lower quality\n",
    "\n",
    "We'll use **vit_h** for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c387aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# SAM model configurations\n",
    "SAM_MODELS = {\n",
    "    'vit_h': {\n",
    "        'url': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth',\n",
    "        'checkpoint': 'sam_vit_h_4b8939.pth'\n",
    "    },\n",
    "    'vit_l': {\n",
    "        'url': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth',\n",
    "        'checkpoint': 'sam_vit_l_0b3195.pth'\n",
    "    },\n",
    "    'vit_b': {\n",
    "        'url': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth',\n",
    "        'checkpoint': 'sam_vit_b_01ec64.pth'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Choose model (vit_h for best quality)\n",
    "MODEL_TYPE = 'vit_h'\n",
    "checkpoint_path = SAM_MODELS[MODEL_TYPE]['checkpoint']\n",
    "\n",
    "# Download if not exists\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(f\"Downloading SAM {MODEL_TYPE} model...\")\n",
    "    urllib.request.urlretrieve(SAM_MODELS[MODEL_TYPE]['url'], checkpoint_path)\n",
    "    print(\"Download complete!\")\n",
    "else:\n",
    "    print(f\"SAM model already downloaded: {checkpoint_path}\")\n",
    "\n",
    "# Load SAM model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Loading SAM model on {device}...\")\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=checkpoint_path)\n",
    "sam.to(device=device)\n",
    "print(\"SAM model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be002d",
   "metadata": {},
   "source": [
    "## 4. Configure Image Paths\n",
    "\n",
    "**Replace these paths with your actual image paths:**\n",
    "- `original_segmentation_map`: Your COCO segmentation map (colored regions on black background)\n",
    "- `controlnet_spatial_image`: Generated with ControlNet + spatial conditioning\n",
    "- `controlnet_no_spatial_image`: Generated with ControlNet without spatial conditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# UPDATE THESE PATHS WITH YOUR IMAGES\n",
    "# ============================================\n",
    "\n",
    "original_segmentation_map = \"path/to/original_segmentation_map.png\"  # COCO segmentation map\n",
    "controlnet_spatial_image = \"path/to/controlnet_with_spatial_conditioning.png\"\n",
    "controlnet_no_spatial_image = \"path/to/controlnet_without_spatial_conditioning.png\"\n",
    "\n",
    "# Verify files exist\n",
    "for path in [original_segmentation_map, controlnet_spatial_image, controlnet_no_spatial_image]:\n",
    "    if Path(path).exists():\n",
    "        print(f\"âœ“ Found: {path}\")\n",
    "    else:\n",
    "        print(f\"âœ— NOT FOUND: {path}\")\n",
    "        print(\"  Please update the path above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a024f0",
   "metadata": {},
   "source": [
    "## 5. Helper Functions for Segmentation & Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0056052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_masks_from_segmentation_map(seg_map_path: str) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract individual masks from a colored segmentation map (e.g., COCO format).\n",
    "    Each unique color represents a different segment.\n",
    "    \n",
    "    Args:\n",
    "        seg_map_path: Path to segmentation map image\n",
    "    \n",
    "    Returns:\n",
    "        List of binary masks, one for each colored region\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    image = cv2.imread(seg_map_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Reshape to list of pixels\n",
    "    pixels = image_rgb.reshape(-1, 3)\n",
    "    \n",
    "    # Find unique colors (excluding black background)\n",
    "    unique_colors = np.unique(pixels, axis=0)\n",
    "    \n",
    "    # Remove black (background) - assuming background is [0, 0, 0]\n",
    "    unique_colors = unique_colors[~np.all(unique_colors == [0, 0, 0], axis=1)]\n",
    "    \n",
    "    print(f\"  Found {len(unique_colors)} unique colored regions\")\n",
    "    \n",
    "    # Create binary mask for each color\n",
    "    masks = []\n",
    "    h, w = image_rgb.shape[:2]\n",
    "    \n",
    "    for color in unique_colors:\n",
    "        # Create mask where this color exists\n",
    "        mask = np.all(image_rgb == color, axis=-1).astype(np.uint8)\n",
    "        \n",
    "        # Only keep masks with reasonable size\n",
    "        if np.sum(mask) > 100:  # At least 100 pixels\n",
    "            masks.append(mask)\n",
    "    \n",
    "    # Sort by area (largest first)\n",
    "    masks = sorted(masks, key=lambda m: m.sum(), reverse=True)\n",
    "    \n",
    "    return masks\n",
    "\n",
    "\n",
    "def segment_image_with_sam(image_path: str, sam_model) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Segment an image using SAM automatic mask generation.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to image\n",
    "        sam_model: Loaded SAM model\n",
    "    \n",
    "    Returns:\n",
    "        List of binary masks\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Generate masks automatically\n",
    "    mask_generator = SamAutomaticMaskGenerator(\n",
    "        model=sam_model,\n",
    "        points_per_side=32,\n",
    "        pred_iou_thresh=0.86,\n",
    "        stability_score_thresh=0.92,\n",
    "        crop_n_layers=1,\n",
    "        crop_n_points_downscale_factor=2,\n",
    "        min_mask_region_area=100,  # Minimum pixels for a valid mask\n",
    "    )\n",
    "    \n",
    "    print(f\"  Generating masks with SAM for {Path(image_path).name}...\")\n",
    "    masks = mask_generator.generate(image_rgb)\n",
    "    \n",
    "    # Extract binary masks\n",
    "    binary_masks = [mask['segmentation'].astype(np.uint8) for mask in masks]\n",
    "    \n",
    "    # Sort by area (largest first)\n",
    "    binary_masks = sorted(binary_masks, key=lambda m: m.sum(), reverse=True)\n",
    "    \n",
    "    return binary_masks\n",
    "\n",
    "\n",
    "def compute_iou(mask1: np.ndarray, mask2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute Intersection over Union between two binary masks.\n",
    "    \"\"\"\n",
    "    intersection = np.logical_and(mask1, mask2).sum()\n",
    "    union = np.logical_or(mask1, mask2).sum()\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "def build_cost_matrix(masks1: List[np.ndarray], masks2: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build cost matrix for Hungarian algorithm.\n",
    "    Cost = 1 - IoU (minimize cost = maximize IoU)\n",
    "    \"\"\"\n",
    "    n1, n2 = len(masks1), len(masks2)\n",
    "    cost_matrix = np.zeros((n1, n2))\n",
    "    \n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            iou = compute_iou(masks1[i], masks2[j])\n",
    "            cost_matrix[i, j] = 1 - iou  # Convert to cost\n",
    "    \n",
    "    return cost_matrix\n",
    "\n",
    "\n",
    "def hungarian_matching(masks1: List[np.ndarray], masks2: List[np.ndarray]) -> Tuple[float, List[Tuple[int, int]], List[float]]:\n",
    "    \"\"\"\n",
    "    Find optimal matching using Hungarian algorithm.\n",
    "    \n",
    "    Returns:\n",
    "        (mean_iou, matching_pairs, individual_ious)\n",
    "    \"\"\"\n",
    "    if len(masks1) == 0 or len(masks2) == 0:\n",
    "        return 0.0, [], []\n",
    "    \n",
    "    # Build cost matrix\n",
    "    cost_matrix = build_cost_matrix(masks1, masks2)\n",
    "    \n",
    "    # Apply Hungarian algorithm\n",
    "    row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    # Calculate IoU for matched pairs\n",
    "    ious = []\n",
    "    matching_pairs = []\n",
    "    \n",
    "    for i, j in zip(row_indices, col_indices):\n",
    "        iou = compute_iou(masks1[i], masks2[j])\n",
    "        ious.append(iou)\n",
    "        matching_pairs.append((i, j))\n",
    "    \n",
    "    mean_iou = np.mean(ious) if ious else 0.0\n",
    "    \n",
    "    return mean_iou, matching_pairs, ious\n",
    "\n",
    "\n",
    "print(\"âœ“ Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778e041",
   "metadata": {},
   "source": [
    "## 6. Extract Masks from Original Segmentation Map & Segment Generated Images\n",
    "\n",
    "- **Original**: Extract colored regions (no SAM needed)\n",
    "- **Generated Images**: Run SAM segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXTRACTING MASKS & SEGMENTING IMAGES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extract masks from original COCO segmentation map\n",
    "print(\"\\n1. Original Segmentation Map (COCO)\")\n",
    "print(\"   Extracting colored regions...\")\n",
    "masks_original = extract_masks_from_segmentation_map(original_segmentation_map)\n",
    "print(f\"   â†’ Extracted {len(masks_original)} segments\")\n",
    "\n",
    "# Segment ControlNet + spatial conditioning with SAM\n",
    "print(\"\\n2. ControlNet + Spatial Conditioning\")\n",
    "masks_spatial = segment_image_with_sam(controlnet_spatial_image, sam)\n",
    "print(f\"   â†’ Found {len(masks_spatial)} segments\")\n",
    "\n",
    "# Segment ControlNet without spatial conditioning with SAM\n",
    "print(\"\\n3. ControlNet without Spatial Conditioning\")\n",
    "masks_no_spatial = segment_image_with_sam(controlnet_no_spatial_image, sam)\n",
    "print(f\"   â†’ Found {len(masks_no_spatial)} segments\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Mask extraction & segmentation complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84493f19",
   "metadata": {},
   "source": [
    "## 7. Visualize Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d621502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_masks(image_path: str, masks: List[np.ndarray], title: str, is_segmap: bool = False):\n",
    "    \"\"\"Visualize image with segmentation overlay.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create colored overlay\n",
    "    overlay = np.zeros_like(image_rgb)\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, len(masks)))\n",
    "    \n",
    "    for idx, mask in enumerate(masks[:20]):  # Show top 20 segments\n",
    "        color = (colors[idx][:3] * 255).astype(np.uint8)\n",
    "        overlay[mask > 0] = color\n",
    "    \n",
    "    # For segmentation map, show it as-is, otherwise blend\n",
    "    if is_segmap:\n",
    "        blended = image_rgb  # Show original colored segments\n",
    "    else:\n",
    "        blended = cv2.addWeighted(image_rgb, 0.5, overlay, 0.5, 0)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.title(f'{title}\\n(Original)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(f'Extracted Masks\\n({len(masks)} total)')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(blended)\n",
    "    plt.title('Segmentation Map' if is_segmap else 'Overlay')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize all three\n",
    "visualize_masks(original_segmentation_map, masks_original, \"Original Segmentation Map\", is_segmap=True)\n",
    "visualize_masks(controlnet_spatial_image, masks_spatial, \"ControlNet + Spatial\")\n",
    "visualize_masks(controlnet_no_spatial_image, masks_no_spatial, \"ControlNet - No Spatial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba93f01",
   "metadata": {},
   "source": [
    "## 8. Run Hungarian Matching & Compute IoU\n",
    "\n",
    "This is the core evaluation step:\n",
    "1. Match segments from **Original** â†” **ControlNet+Spatial**\n",
    "2. Match segments from **Original** â†” **ControlNet-NoSpatial**\n",
    "3. Compare IoU scores to determine quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f908830",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HUNGARIAN MATCHING ALGORITHM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Matching 1: Original vs ControlNet + Spatial\n",
    "print(\"\\n1ï¸âƒ£  Original vs ControlNet + Spatial Conditioning\")\n",
    "print(\"-\" * 70)\n",
    "mean_iou_spatial, pairs_spatial, ious_spatial = hungarian_matching(masks_original, masks_spatial)\n",
    "print(f\"   Matched pairs: {len(pairs_spatial)}\")\n",
    "print(f\"   Mean IoU: {mean_iou_spatial:.4f}\")\n",
    "print(f\"   Max IoU: {max(ious_spatial):.4f}\" if ious_spatial else \"   Max IoU: 0.0000\")\n",
    "print(f\"   Min IoU: {min(ious_spatial):.4f}\" if ious_spatial else \"   Min IoU: 0.0000\")\n",
    "\n",
    "# Matching 2: Original vs ControlNet - No Spatial\n",
    "print(\"\\n2ï¸âƒ£  Original vs ControlNet - No Spatial Conditioning\")\n",
    "print(\"-\" * 70)\n",
    "mean_iou_no_spatial, pairs_no_spatial, ious_no_spatial = hungarian_matching(masks_original, masks_no_spatial)\n",
    "print(f\"   Matched pairs: {len(pairs_no_spatial)}\")\n",
    "print(f\"   Mean IoU: {mean_iou_no_spatial:.4f}\")\n",
    "print(f\"   Max IoU: {max(ious_no_spatial):.4f}\" if ious_no_spatial else \"   Max IoU: 0.0000\")\n",
    "print(f\"   Min IoU: {min(ious_no_spatial):.4f}\" if ious_no_spatial else \"   Min IoU: 0.0000\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370e4b2",
   "metadata": {},
   "source": [
    "## 9. Final Results & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f504a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "improvement = mean_iou_spatial - mean_iou_no_spatial\n",
    "improvement_percent = (improvement / mean_iou_no_spatial * 100) if mean_iou_no_spatial > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ¯ FINAL QUALITY METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nðŸ“Š IoU Scores:\")\n",
    "print(f\"   Original vs ControlNet+Spatial:    {mean_iou_spatial:.4f}\")\n",
    "print(f\"   Original vs ControlNet-NoSpatial:  {mean_iou_no_spatial:.4f}\")\n",
    "print(f\"\\nðŸ“ˆ Improvement from Spatial Conditioning:\")\n",
    "print(f\"   Absolute: {improvement:+.4f}\")\n",
    "print(f\"   Relative: {improvement_percent:+.2f}%\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "if improvement > 0:\n",
    "    print(\"\\nâœ… RESULT: Spatial conditioning IMPROVES spatial structure preservation\")\n",
    "    print(f\"   â†’ ControlNet with segmentation maps better preserves object layout!\")\n",
    "elif improvement < 0:\n",
    "    print(\"\\nâŒ RESULT: Spatial conditioning DECREASES spatial structure preservation\")\n",
    "    print(f\"   â†’ Unexpected: spatial conditioning performed worse\")\n",
    "else:\n",
    "    print(\"\\nâž– RESULT: No difference detected\")\n",
    "    print(f\"   â†’ Both methods preserve spatial structure equally\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac64cbfd",
   "metadata": {},
   "source": [
    "## 10. Detailed Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Load images\n",
    "img_orig = cv2.cvtColor(cv2.imread(original_segmentation_map), cv2.COLOR_BGR2RGB)\n",
    "img_spatial = cv2.cvtColor(cv2.imread(controlnet_spatial_image), cv2.COLOR_BGR2RGB)\n",
    "img_no_spatial = cv2.cvtColor(cv2.imread(controlnet_no_spatial_image), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Row 1: Original images\n",
    "axes[0, 0].imshow(img_orig)\n",
    "axes[0, 0].set_title('Original Segmentation Map\\n(COCO Dataset)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(img_spatial)\n",
    "axes[0, 1].set_title(f'ControlNet + Spatial\\nIoU: {mean_iou_spatial:.4f}', \n",
    "                     fontsize=14, fontweight='bold', color='green' if improvement > 0 else 'red')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(img_no_spatial)\n",
    "axes[0, 2].set_title(f'ControlNet - No Spatial\\nIoU: {mean_iou_no_spatial:.4f}', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Row 2: Mask overlays\n",
    "def create_overlay(masks, image, blend: bool = True):\n",
    "    overlay = np.zeros_like(image)\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, min(len(masks), 20)))\n",
    "    for idx, mask in enumerate(masks[:20]):\n",
    "        color = (colors[idx][:3] * 255).astype(np.uint8)\n",
    "        overlay[mask > 0] = color\n",
    "    if blend:\n",
    "        return cv2.addWeighted(image, 0.4, overlay, 0.6, 0)\n",
    "    return overlay\n",
    "\n",
    "axes[1, 0].imshow(create_overlay(masks_original, img_orig, blend=False))\n",
    "axes[1, 0].set_title(f'Extracted Masks\\n({len(masks_original)} regions)', fontsize=12)\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(create_overlay(masks_spatial, img_spatial))\n",
    "axes[1, 1].set_title(f'SAM Segments\\n({len(masks_spatial)} total)', fontsize=12)\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(create_overlay(masks_no_spatial, img_no_spatial))\n",
    "axes[1, 2].set_title(f'SAM Segments\\n({len(masks_no_spatial)} total)', fontsize=12)\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.suptitle('Segmentation Map vs Generated Images - Quality Comparison', fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6714f49",
   "metadata": {},
   "source": [
    "## 11. IoU Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e62f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IoU distributions\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram comparison\n",
    "bins = np.linspace(0, 1, 21)\n",
    "ax1.hist(ious_spatial, bins=bins, alpha=0.6, label='With Spatial', color='green', edgecolor='black')\n",
    "ax1.hist(ious_no_spatial, bins=bins, alpha=0.6, label='Without Spatial', color='red', edgecolor='black')\n",
    "ax1.axvline(mean_iou_spatial, color='green', linestyle='--', linewidth=2, label=f'Mean (Spatial): {mean_iou_spatial:.3f}')\n",
    "ax1.axvline(mean_iou_no_spatial, color='red', linestyle='--', linewidth=2, label=f'Mean (No-Spatial): {mean_iou_no_spatial:.3f}')\n",
    "ax1.set_xlabel('IoU Score', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.set_title('IoU Distribution Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "data_to_plot = [ious_spatial, ious_no_spatial]\n",
    "bp = ax2.boxplot(data_to_plot, labels=['With Spatial', 'Without Spatial'], \n",
    "                  patch_artist=True, widths=0.6)\n",
    "bp['boxes'][0].set_facecolor('lightgreen')\n",
    "bp['boxes'][1].set_facecolor('lightcoral')\n",
    "ax2.set_ylabel('IoU Score', fontsize=12)\n",
    "ax2.set_title('IoU Score Distribution (Boxplot)', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nðŸ“Š Statistical Summary:\")\n",
    "print(\"\\nWith Spatial Conditioning:\")\n",
    "print(f\"  Mean:   {np.mean(ious_spatial):.4f}\")\n",
    "print(f\"  Median: {np.median(ious_spatial):.4f}\")\n",
    "print(f\"  Std:    {np.std(ious_spatial):.4f}\")\n",
    "\n",
    "print(\"\\nWithout Spatial Conditioning:\")\n",
    "print(f\"  Mean:   {np.mean(ious_no_spatial):.4f}\")\n",
    "print(f\"  Median: {np.median(ious_no_spatial):.4f}\")\n",
    "print(f\"  Std:    {np.std(ious_no_spatial):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b1ec6",
   "metadata": {},
   "source": [
    "## 12. Summary & Interpretation\n",
    "\n",
    "### How This Metric Works:\n",
    "\n",
    "1. **Extract Original Masks**: Parse colored regions from COCO segmentation map\n",
    "2. **SAM Segmentation**: Generate masks for both ControlNet outputs\n",
    "3. **Class-Agnostic Matching**: Treats all segments equally (no class labels needed)\n",
    "4. **Hungarian Algorithm**: Finds optimal one-to-one matching that maximizes total IoU\n",
    "5. **Quality Score**: Mean IoU indicates how well spatial structure is preserved\n",
    "\n",
    "### Interpreting Results:\n",
    "\n",
    "- **IoU > 0.6**: Excellent spatial preservation - generated image closely matches segmentation structure\n",
    "- **0.4 < IoU < 0.6**: Good spatial preservation - reasonable object layout matching\n",
    "- **0.2 < IoU < 0.4**: Moderate spatial preservation - some spatial structure retained\n",
    "- **IoU < 0.2**: Poor spatial preservation - significant deviation from original layout\n",
    "\n",
    "### Key Advantages:\n",
    "\n",
    "âœ… **Works with COCO segmentation maps** - directly uses colored regions  \n",
    "âœ… **Class-agnostic** - no need to know object classes  \n",
    "âœ… **Optimal matching** via Hungarian algorithm  \n",
    "âœ… **Interpretable** - IoU is well-understood  \n",
    "âœ… **Quantitative** - produces comparable scores  \n",
    "\n",
    "### Use Cases:\n",
    "\n",
    "- Evaluate ControlNet spatial conditioning quality\n",
    "- Validate that segmentation-conditioned generation preserves layout\n",
    "- Compare ControlNet with/without spatial conditioning\n",
    "- Benchmark different generation methods"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
