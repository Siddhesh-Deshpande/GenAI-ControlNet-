{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "31892e49",
      "metadata": {
        "id": "31892e49"
      },
      "source": [
        "# ControlNet Quality Metric using SAM Segmentation & Hungarian Matching\n",
        "\n",
        "This notebook evaluates the quality of ControlNet image generation by:\n",
        "1. **Extracting segments** from the original COCO segmentation map (colored regions)\n",
        "2. **Segmenting** the two generated images using SAM (Segment Anything Model):\n",
        "   - ControlNet + Spatial Conditioning (conditioned on segmentation maps)\n",
        "   - ControlNet without Spatial Conditioning\n",
        "3. **Treating all segments as class-agnostic** (same class)\n",
        "4. **Using Hungarian algorithm** to find optimal segment matching\n",
        "5. **Computing maximum IoU** between matched segments\n",
        "\n",
        "**Key Insight**: The original image is a segmentation map from COCO dataset with colored regions. We extract masks from these colored regions and match them against SAM-generated masks from the two generated images using Hungarian matching to maximize IoU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c9bb135",
      "metadata": {
        "id": "2c9bb135"
      },
      "source": [
        "## 1. Install Required Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad75c430",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad75c430",
        "outputId": "c335535e-9ccb-4a1c-8f3b-37cb14c3cbd7"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision\n",
        "!pip install -q opencv-python matplotlib numpy scipy\n",
        "!pip install -q git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install -q pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d99c2e66",
      "metadata": {
        "id": "d99c2e66"
      },
      "source": [
        "## 2. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "defdfe7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "defdfe7e",
        "outputId": "c293b8ff-7473-429f-c9fa-2561ff555573"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb17c5cd",
      "metadata": {
        "id": "bb17c5cd"
      },
      "source": [
        "## 3. Download and Load SAM Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c387aa06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c387aa06",
        "outputId": "10135eed-5d10-4b10-fbe7-7c4f557b5b71"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import os\n",
        "\n",
        "\n",
        "SAM_MODELS = {\n",
        "    'vit_h': {\n",
        "        'url': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth',\n",
        "        'checkpoint': 'sam_vit_h_4b8939.pth'\n",
        "    },\n",
        "    'vit_l': {\n",
        "        'url': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth',\n",
        "        'checkpoint': 'sam_vit_l_0b3195.pth'\n",
        "    },\n",
        "    'vit_b': {\n",
        "        'url': 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth',\n",
        "        'checkpoint': 'sam_vit_b_01ec64.pth'\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "MODEL_TYPE = 'vit_h'\n",
        "checkpoint_path = SAM_MODELS[MODEL_TYPE]['checkpoint']\n",
        "\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(f\"Downloading SAM {MODEL_TYPE} model...\")\n",
        "    urllib.request.urlretrieve(SAM_MODELS[MODEL_TYPE]['url'], checkpoint_path)\n",
        "    print(\"Download complete!\")\n",
        "else:\n",
        "    print(f\"SAM model already downloaded: {checkpoint_path}\")\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Loading SAM model on {device}...\")\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=checkpoint_path)\n",
        "sam.to(device=device)\n",
        "print(\"SAM model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "486e351f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "486e351f",
        "outputId": "e52a4dbd-2e41-4abc-b202-dbe9d0ab8b6a"
      },
      "outputs": [],
      "source": [
        "original_segmentation_map = \"/content/input.jpeg\"  # COCO segmentation map\n",
        "controlnet_spatial_image = \"/content/controlnetwithspatial.jpeg\"\n",
        "controlnet_no_spatial_image = \"/content/withoutspatial.jpeg\"\n",
        "\n",
        "for path in [original_segmentation_map, controlnet_spatial_image, controlnet_no_spatial_image]:\n",
        "    if Path(path).exists():\n",
        "        print(f\"✓ Found: {path}\")\n",
        "    else:\n",
        "        print(f\"✗ NOT FOUND: {path}\")\n",
        "        print(\"  Please update the path above!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7a024f0",
      "metadata": {
        "id": "e7a024f0"
      },
      "source": [
        "## 4. Helper Functions for Segmentation & Matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0056052",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0056052",
        "outputId": "68e2022f-2d03-4c4c-a0ee-529296df38f1"
      },
      "outputs": [],
      "source": [
        "def extract_masks_from_segmentation_map(seg_map_path: str) -> List[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Extract individual masks from a colored segmentation map (e.g., COCO format).\n",
        "    Each unique color represents a different segment.\n",
        "\n",
        "    Args:\n",
        "        seg_map_path: Path to segmentation map image\n",
        "\n",
        "    Returns:\n",
        "        List of binary masks, one for each colored region\n",
        "    \"\"\"\n",
        "    image = cv2.imread(seg_map_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Reshape to list of pixels\n",
        "    pixels = image_rgb.reshape(-1, 3)\n",
        "\n",
        "    # Find unique colors (excluding black background)\n",
        "    unique_colors = np.unique(pixels, axis=0)\n",
        "\n",
        "    # Remove black (background) - assuming background is [0, 0, 0]\n",
        "    unique_colors = unique_colors[~np.all(unique_colors == [0, 0, 0], axis=1)]\n",
        "\n",
        "    print(f\"  Found {len(unique_colors)} unique colored regions\")\n",
        "\n",
        "    # Create binary mask for each color\n",
        "    masks = []\n",
        "    h, w = image_rgb.shape[:2]\n",
        "\n",
        "    for color in unique_colors:\n",
        "        # Create mask where this color exists\n",
        "        mask = np.all(image_rgb == color, axis=-1).astype(np.uint8)\n",
        "\n",
        "        # Only keep masks with reasonable size\n",
        "        if np.sum(mask) > 100:  # At least 100 pixels\n",
        "            masks.append(mask)\n",
        "\n",
        "    # Sort by area (largest first)\n",
        "    masks = sorted(masks, key=lambda m: m.sum(), reverse=True)\n",
        "\n",
        "    return masks\n",
        "\n",
        "\n",
        "def segment_image_with_sam(image_path: str, sam_model) -> List[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Segment an image using SAM automatic mask generation.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to image\n",
        "        sam_model: Loaded SAM model\n",
        "\n",
        "    Returns:\n",
        "        List of binary masks\n",
        "    \"\"\"\n",
        "    # Read image\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Generate masks automatically\n",
        "    mask_generator = SamAutomaticMaskGenerator(\n",
        "        model=sam_model,\n",
        "        points_per_side=32,\n",
        "        pred_iou_thresh=0.86,\n",
        "        stability_score_thresh=0.92,\n",
        "        crop_n_layers=1,\n",
        "        crop_n_points_downscale_factor=2,\n",
        "        min_mask_region_area=100,  # Minimum pixels for a valid mask\n",
        "    )\n",
        "\n",
        "    print(f\"  Generating masks with SAM for {Path(image_path).name}...\")\n",
        "    masks = mask_generator.generate(image_rgb)\n",
        "\n",
        "    # Extract binary masks\n",
        "    binary_masks = [mask['segmentation'].astype(np.uint8) for mask in masks]\n",
        "\n",
        "    # Sort by area (largest first)\n",
        "    binary_masks = sorted(binary_masks, key=lambda m: m.sum(), reverse=True)\n",
        "\n",
        "    return binary_masks\n",
        "\n",
        "\n",
        "def compute_iou(mask1: np.ndarray, mask2: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Compute Intersection over Union between two binary masks.\n",
        "    \"\"\"\n",
        "    intersection = np.logical_and(mask1, mask2).sum()\n",
        "    union = np.logical_or(mask1, mask2).sum()\n",
        "\n",
        "    if union == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return intersection / union\n",
        "\n",
        "\n",
        "def build_cost_matrix(masks1: List[np.ndarray], masks2: List[np.ndarray]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Build cost matrix for Hungarian algorithm.\n",
        "    Cost = 1 - IoU (minimize cost = maximize IoU)\n",
        "    \"\"\"\n",
        "    n1, n2 = len(masks1), len(masks2)\n",
        "    cost_matrix = np.zeros((n1, n2))\n",
        "\n",
        "    for i in range(n1):\n",
        "        for j in range(n2):\n",
        "            iou = compute_iou(masks1[i], masks2[j])\n",
        "            cost_matrix[i, j] = 1 - iou  # Convert to cost\n",
        "\n",
        "    return cost_matrix\n",
        "\n",
        "\n",
        "def hungarian_matching(masks1: List[np.ndarray], masks2: List[np.ndarray]) -> Tuple[float, List[Tuple[int, int]], List[float]]:\n",
        "    \"\"\"\n",
        "    Find optimal matching using Hungarian algorithm.\n",
        "\n",
        "    Returns:\n",
        "        (mean_iou, matching_pairs, individual_ious)\n",
        "    \"\"\"\n",
        "    if len(masks1) == 0 or len(masks2) == 0:\n",
        "        return 0.0, [], []\n",
        "\n",
        "    # Build cost matrix\n",
        "    cost_matrix = build_cost_matrix(masks1, masks2)\n",
        "\n",
        "    # Apply Hungarian algorithm\n",
        "    row_indices, col_indices = linear_sum_assignment(cost_matrix)\n",
        "\n",
        "    # Calculate IoU for matched pairs\n",
        "    ious = []\n",
        "    matching_pairs = []\n",
        "\n",
        "    for i, j in zip(row_indices, col_indices):\n",
        "        iou = compute_iou(masks1[i], masks2[j])\n",
        "        ious.append(iou)\n",
        "        matching_pairs.append((i, j))\n",
        "\n",
        "    mean_iou = np.mean(ious) if ious else 0.0\n",
        "\n",
        "    return mean_iou, matching_pairs, ious\n",
        "\n",
        "\n",
        "print(\"✓ Helper functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b778e041",
      "metadata": {
        "id": "b778e041"
      },
      "source": [
        "## 5. Extract Masks from Original Segmentation Map & Segment Generated Images\n",
        "\n",
        "- **Original**: Extract colored regions (no SAM needed)\n",
        "- **Generated Images**: Run SAM segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9622202a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9622202a",
        "outputId": "0bb1998a-b5f4-468c-ef84-1451e928e33c"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"EXTRACTING MASKS & SEGMENTING IMAGES\")\n",
        "\n",
        "# Extract masks from original COCO segmentation map\n",
        "print(\"\\n1. Original Segmentation Map (COCO)\")\n",
        "print(\"   Extracting colored regions...\")\n",
        "masks_original = extract_masks_from_segmentation_map(original_segmentation_map)\n",
        "print(f\"   → Extracted {len(masks_original)} segments\")\n",
        "\n",
        "# Segment ControlNet + spatial conditioning with SAM\n",
        "print(\"\\n2. ControlNet + Spatial Conditioning\")\n",
        "masks_spatial = segment_image_with_sam(controlnet_spatial_image, sam)\n",
        "print(f\"   → Found {len(masks_spatial)} segments\")\n",
        "\n",
        "# Segment ControlNet without spatial conditioning with SAM\n",
        "print(\"\\n3. ControlNet without Spatial Conditioning\")\n",
        "masks_no_spatial = segment_image_with_sam(controlnet_no_spatial_image, sam)\n",
        "print(f\"   → Found {len(masks_no_spatial)} segments\")\n",
        "\n",
        "\n",
        "print(\"Mask extraction & segmentation complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84493f19",
      "metadata": {
        "id": "84493f19"
      },
      "source": [
        "## 6. Visualize Segmentation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d621502a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d621502a",
        "outputId": "81e1e18d-c9ae-41e5-b7d7-20d2c30da1eb"
      },
      "outputs": [],
      "source": [
        "def visualize_masks(image_path: str, masks: List[np.ndarray], title: str, is_segmap: bool = False):\n",
        "    \"\"\"Visualize image with segmentation overlay.\"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create colored overlay\n",
        "    overlay = np.zeros_like(image_rgb)\n",
        "    colors = plt.cm.tab20(np.linspace(0, 1, len(masks)))\n",
        "\n",
        "    for idx, mask in enumerate(masks[:20]):  # Show top 20 segments\n",
        "        color = (colors[idx][:3] * 255).astype(np.uint8)\n",
        "        overlay[mask > 0] = color\n",
        "\n",
        "    # For segmentation map, show it as-is, otherwise blend\n",
        "    if is_segmap:\n",
        "        blended = image_rgb  # Show original colored segments\n",
        "    else:\n",
        "        blended = cv2.addWeighted(image_rgb, 0.5, overlay, 0.5, 0)\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.title(f'{title}\\n(Original)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(overlay)\n",
        "    plt.title(f'Extracted Masks\\n({len(masks)} total)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(blended)\n",
        "    plt.title('Segmentation Map' if is_segmap else 'Overlay')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "visualize_masks(original_segmentation_map, masks_original, \"Original Segmentation Map\", is_segmap=True)\n",
        "visualize_masks(controlnet_spatial_image, masks_spatial, \"ControlNet + Spatial\")\n",
        "visualize_masks(controlnet_no_spatial_image, masks_no_spatial, \"ControlNet - No Spatial\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba93f01",
      "metadata": {
        "id": "dba93f01"
      },
      "source": [
        "## 7. Run Hungarian Matching & Compute IoU\n",
        "\n",
        "This is the core evaluation step:\n",
        "1. Match segments from **Original** ↔ **ControlNet+Spatial**\n",
        "2. Match segments from **Original** ↔ **ControlNet-NoSpatial**\n",
        "3. Compare IoU scores to determine quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f908830",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f908830",
        "outputId": "614e26f7-d324-4a5b-9b9c-19241f59924b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Matching 1: Original vs ControlNet + Spatial\n",
        "print(\"\\n Original vs ControlNet + Spatial Conditioning\")\n",
        "\n",
        "mean_iou_spatial, pairs_spatial, ious_spatial = hungarian_matching(masks_original, masks_spatial)\n",
        "print(f\"   Matched pairs: {len(pairs_spatial)}\")\n",
        "print(f\"   Mean IoU: {mean_iou_spatial:.4f}\")\n",
        "print(f\"   Max IoU: {max(ious_spatial):.4f}\" if ious_spatial else \"   Max IoU: 0.0000\")\n",
        "print(f\"   Min IoU: {min(ious_spatial):.4f}\" if ious_spatial else \"   Min IoU: 0.0000\")\n",
        "\n",
        "# Matching 2: Original vs ControlNet - No Spatial\n",
        "print(\"\\n  Original vs ControlNet - No Spatial Conditioning\")\n",
        "print(\"-\" * 70)\n",
        "mean_iou_no_spatial, pairs_no_spatial, ious_no_spatial = hungarian_matching(masks_original, masks_no_spatial)\n",
        "print(f\"   Matched pairs: {len(pairs_no_spatial)}\")\n",
        "print(f\"   Mean IoU: {mean_iou_no_spatial:.4f}\")\n",
        "print(f\"   Max IoU: {max(ious_no_spatial):.4f}\" if ious_no_spatial else \"   Max IoU: 0.0000\")\n",
        "print(f\"   Min IoU: {min(ious_no_spatial):.4f}\" if ious_no_spatial else \"   Min IoU: 0.0000\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0370e4b2",
      "metadata": {
        "id": "0370e4b2"
      },
      "source": [
        "## 8. Final Results & Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f504a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7f504a2",
        "outputId": "16019832-2388-4a89-c7d0-6adeb738da79"
      },
      "outputs": [],
      "source": [
        "improvement = mean_iou_spatial - mean_iou_no_spatial\n",
        "improvement_percent = (improvement / mean_iou_no_spatial * 100) if mean_iou_no_spatial > 0 else 0\n",
        "\n",
        "\n",
        "print(\" FINAL QUALITY METRICS\")\n",
        "\n",
        "print(f\"\\n IoU Scores:\")\n",
        "print(f\"   Original vs ControlNet+Spatial:    {mean_iou_spatial:.4f}\")\n",
        "print(f\"   Original vs ControlNet-NoSpatial:  {mean_iou_no_spatial:.4f}\")\n",
        "print(f\"\\n Improvement from Spatial Conditioning:\")\n",
        "print(f\"   Absolute: {improvement:+.4f}\")\n",
        "print(f\"   Relative: {improvement_percent:+.2f}%\")\n",
        "\n",
        "if improvement > 0:\n",
        "    print(\"\\nRESULT: Spatial conditioning IMPROVES spatial structure preservation\")\n",
        "    print(f\"   → ControlNet with segmentation maps better preserves object layout!\")\n",
        "elif improvement < 0:\n",
        "    print(\"\\n RESULT: Spatial conditioning DECREASES spatial structure preservation\")\n",
        "    print(f\"   → Unexpected: spatial conditioning performed worse\")\n",
        "else:\n",
        "    print(\"\\n RESULT: No difference detected\")\n",
        "    print(f\"   → Both methods preserve spatial structure equally\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac64cbfd",
      "metadata": {
        "id": "ac64cbfd"
      },
      "source": [
        "## 9. Detailed Visualization of Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d8b8480",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        },
        "id": "6d8b8480",
        "outputId": "2a2e7498-5d8d-47b5-82bf-21aa56276dbf"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "img_orig = cv2.cvtColor(cv2.imread(original_segmentation_map), cv2.COLOR_BGR2RGB)\n",
        "img_spatial = cv2.cvtColor(cv2.imread(controlnet_spatial_image), cv2.COLOR_BGR2RGB)\n",
        "img_no_spatial = cv2.cvtColor(cv2.imread(controlnet_no_spatial_image), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Row 1: Original images\n",
        "axes[0, 0].imshow(img_orig)\n",
        "axes[0, 0].set_title('Original Segmentation Map\\n(COCO Dataset)', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "axes[0, 1].imshow(img_spatial)\n",
        "axes[0, 1].set_title(f'ControlNet + Spatial\\nIoU: {mean_iou_spatial:.4f}',\n",
        "                     fontsize=14, fontweight='bold', color='green' if improvement > 0 else 'red')\n",
        "axes[0, 1].axis('off')\n",
        "\n",
        "axes[0, 2].imshow(img_no_spatial)\n",
        "axes[0, 2].set_title(f'ControlNet - No Spatial\\nIoU: {mean_iou_no_spatial:.4f}',\n",
        "                     fontsize=14, fontweight='bold')\n",
        "axes[0, 2].axis('off')\n",
        "\n",
        "# Row 2: Mask overlays\n",
        "def create_overlay(masks, image, blend: bool = True):\n",
        "    overlay = np.zeros_like(image)\n",
        "    colors = plt.cm.tab20(np.linspace(0, 1, min(len(masks), 20)))\n",
        "    for idx, mask in enumerate(masks[:20]):\n",
        "        color = (colors[idx][:3] * 255).astype(np.uint8)\n",
        "        overlay[mask > 0] = color\n",
        "    if blend:\n",
        "        return cv2.addWeighted(image, 0.4, overlay, 0.6, 0)\n",
        "    return overlay\n",
        "\n",
        "axes[1, 0].imshow(create_overlay(masks_original, img_orig, blend=False))\n",
        "axes[1, 0].set_title(f'Extracted Masks\\n({len(masks_original)} regions)', fontsize=12)\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "axes[1, 1].imshow(create_overlay(masks_spatial, img_spatial))\n",
        "axes[1, 1].set_title(f'SAM Segments\\n({len(masks_spatial)} total)', fontsize=12)\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "axes[1, 2].imshow(create_overlay(masks_no_spatial, img_no_spatial))\n",
        "axes[1, 2].set_title(f'SAM Segments\\n({len(masks_no_spatial)} total)', fontsize=12)\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "plt.suptitle('Segmentation Map vs Generated Images - Quality Comparison', fontsize=16, fontweight='bold', y=0.98)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
